{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31501 images belonging to 2 classes.\n",
      "Found 7874 images belonging to 2 classes.\n",
      "Found 8617 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "1969/1969 [==============================] - 766s 386ms/step - loss: 0.1010 - accuracy: 0.9655 - val_loss: 0.0633 - val_accuracy: 0.9765\n",
      "\n",
      "Testing loss: 0.4057602882385254, acc: 0.8082859516143799\n",
      "\n",
      "Epoch 2/50\n",
      "1969/1969 [==============================] - 673s 342ms/step - loss: 0.0230 - accuracy: 0.9914 - val_loss: 0.0353 - val_accuracy: 0.9868\n",
      "\n",
      "Testing loss: 0.3742777109146118, acc: 0.8116514086723328\n",
      "\n",
      "Epoch 3/50\n",
      "1969/1969 [==============================] - 644s 327ms/step - loss: 0.0185 - accuracy: 0.9920 - val_loss: 0.0596 - val_accuracy: 0.9793\n",
      "\n",
      "Testing loss: 0.4517914652824402, acc: 0.8014389872550964\n",
      "\n",
      "Epoch 4/50\n",
      "1969/1969 [==============================] - 659s 335ms/step - loss: 0.0179 - accuracy: 0.9924 - val_loss: 0.0976 - val_accuracy: 0.9577\n",
      "\n",
      "Testing loss: 0.3798963725566864, acc: 0.8354415893554688\n",
      "\n",
      "Epoch 5/50\n",
      "1969/1969 [==============================] - 685s 348ms/step - loss: 0.0139 - accuracy: 0.9944 - val_loss: 0.0561 - val_accuracy: 0.9783\n",
      "\n",
      "Testing loss: 0.45407235622406006, acc: 0.7973772883415222\n",
      "\n",
      "Epoch 6/50\n",
      "1969/1969 [==============================] - 693s 352ms/step - loss: 0.0110 - accuracy: 0.9954 - val_loss: 0.1116 - val_accuracy: 0.9704\n",
      "\n",
      "Testing loss: 0.5839694738388062, acc: 0.7951723337173462\n",
      "\n",
      "Epoch 7/50\n",
      "1969/1969 [==============================] - 683s 347ms/step - loss: 0.0150 - accuracy: 0.9934 - val_loss: 0.0374 - val_accuracy: 0.9877\n",
      "\n",
      "Testing loss: 0.5746597051620483, acc: 0.7349425554275513\n",
      "\n",
      "Epoch 8/50\n",
      "1969/1969 [==============================] - 691s 351ms/step - loss: 0.0101 - accuracy: 0.9956 - val_loss: 0.0607 - val_accuracy: 0.9798\n",
      "\n",
      "Testing loss: 0.4157973527908325, acc: 0.8544737100601196\n",
      "\n",
      "Epoch 9/50\n",
      "1969/1969 [==============================] - 709s 360ms/step - loss: 0.0104 - accuracy: 0.9957 - val_loss: 0.0775 - val_accuracy: 0.9681\n",
      "\n",
      "Testing loss: 0.5073381662368774, acc: 0.8010908961296082\n",
      "\n",
      "Epoch 10/50\n",
      "1969/1969 [==============================] - 698s 354ms/step - loss: 0.0089 - accuracy: 0.9968 - val_loss: 0.0436 - val_accuracy: 0.9854\n",
      "\n",
      "Testing loss: 0.9638869166374207, acc: 0.7017523646354675\n",
      "\n",
      "Epoch 11/50\n",
      "1969/1969 [==============================] - 676s 343ms/step - loss: 0.0102 - accuracy: 0.9957 - val_loss: 0.0501 - val_accuracy: 0.9821\n",
      "\n",
      "Testing loss: 0.903732180595398, acc: 0.6913079023361206\n",
      "\n",
      "Epoch 12/50\n",
      "1969/1969 [==============================] - 681s 346ms/step - loss: 0.0086 - accuracy: 0.9963 - val_loss: 0.0860 - val_accuracy: 0.9738\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Testing loss: 0.3742777109146118, acc: 0.8116514086723328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import cv2 \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import Activation,Conv2D,Dense,MaxPool2D,Dropout,Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure, imshow, axis\n",
    "from matplotlib.image import imread\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from tensorflow.keras.applications import InceptionV3,Xception,VGG16\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras import Model\n",
    "from keras.layers import Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "Base_directory = '/kaggle/input/flamedatasetfireclassification'\n",
    "test_path = 'Test/Test'\n",
    "Training_path = 'Training/Training'\n",
    "input_shape = (254,254,3)\n",
    "batch = 16\n",
    "labels = ['Fire','No_Fire']\n",
    "Full_Training_path = '{0}/{1}'.format(Base_directory,Training_path)\n",
    "Full_Test_path = '{0}/{1}'.format(Base_directory,test_path)\n",
    "train_images = ImageDataGenerator(rotation_range=45,\n",
    "                                 horizontal_flip=True,\n",
    "                                 vertical_flip=True,\n",
    "                                 rescale=1.0/255,\n",
    "                                 zoom_range=0.4,\n",
    "                                 shear_range=0.2,\n",
    "                                 fill_mode='nearest',\n",
    "                                 validation_split=0.2)\n",
    "\n",
    "train_generator = train_images.flow_from_directory(Full_Training_path, \n",
    "                                               target_size=(254,254),\n",
    "                                               color_mode='rgb',\n",
    "                                               class_mode='binary',\n",
    "                                               batch_size=batch,\n",
    "                                               #shuffle=True,\n",
    "                                               subset='training')\n",
    "\n",
    "validation_generator = train_images.flow_from_directory(Full_Training_path, \n",
    "                                                    target_size=(254,254),\n",
    "                                                    color_mode='rgb',\n",
    "                                                    class_mode='binary',\n",
    "                                                    batch_size=batch,\n",
    "                                                   # shuffle=True,\n",
    "                                                    subset='validation')\n",
    "\n",
    "test_images = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "test_generator = test_images.flow_from_directory(Full_Test_path, \n",
    "                                                target_size=(254,254), \n",
    "                                                color_mode='rgb', \n",
    "                                                class_mode='binary',\n",
    "                                                shuffle=False,\n",
    "                                                batch_size=batch)\n",
    "\n",
    "\n",
    "# create model\n",
    "img_input = Input(shape=input_shape)\n",
    "\n",
    "model = VGG16(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=img_input,\n",
    "    input_shape=input_shape,\n",
    "    pooling='avg'\n",
    ")\n",
    "last_layer = model.output\n",
    "x = Flatten(name='flatten')(last_layer)\n",
    "x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "out = Dense(1, kernel_regularizer=tf.keras.regularizers.l2(0.01),activation\n",
    "             ='linear')(x)  ## 2 classes\n",
    "model = Model(img_input, out)\n",
    "\n",
    "# for layer in model.layers[:-80]:\n",
    "     layer.trainable = False\n",
    "    \n",
    "from keras.callbacks import Callback\n",
    "\n",
    "class TestCallback(Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        testset = self.test_data\n",
    "        loss, acc = self.model.evaluate(testset, verbose=0)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))\n",
    "        \n",
    "my_callbacks = [\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1),\n",
    "    ModelCheckpoint(filepath='VGG16_{epoch:02d}_{val_accuracy:.04f}.h5',\n",
    "                    save_best_only=False),\n",
    "    TestCallback(test_generator)]       \n",
    "\n",
    "model.compile( loss = 'hinge',\n",
    "      optimizer='AdaMax',  #AdaMax\n",
    "      metrics='accuracy')\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"VGG16_saved_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "    \n",
    "history = model.fit(train_generator,\n",
    "            epochs=50,\n",
    "            validation_data = validation_generator,            \n",
    "            callbacks=my_callbacks,\n",
    "            verbose=1    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
